{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a30efc0-0544-41c4-8f4c-f9d20d1dd7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ed5c628-b027-40c4-9e0f-1360e81bc498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   title   10 non-null     object\n",
      " 1   text    10 non-null     object\n",
      " 2   source  10 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 368.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "fairy_tales = pd.read_csv(\"../data/fairy_tales.csv\")\n",
    "\n",
    "fairy_tales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "127e3f92-a7ba-48b7-887f-b960687b80fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "231df38e-f7c0-4385-a83c-723cd5456b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3555\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "corpus = fairy_tales['text'].str.lower().tolist()\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "print(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "779acdd1-dfd1-4f7c-be0d-745a7a1f7564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8472bf79-3c1f-42bb-84d5-88f8ae47a001",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 50\n",
    "\n",
    "input_sequences = []\n",
    "\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "\n",
    "        if len(n_gram_sequence) <= MAX_SEQ_LEN:\n",
    "            input_sequences.append(n_gram_sequence)\n",
    "\n",
    "max_sequence_len = min(max([len(x) for x in input_sequences]), MAX_SEQ_LEN)\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "xs = input_sequences[:,:-1]\n",
    "labels = input_sequences[:,-1]\n",
    "\n",
    "ys = keras.utils.to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdb060db-1f60-4bd9-bda6-e7647749c754",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f20fe23b-f1cb-4973-a4c1-3097948a4b45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 3s 80ms/step - loss: 7.8832 - accuracy: 0.0163\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 6.3272 - accuracy: 0.0184\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 5.8404 - accuracy: 0.0347\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 5.6513 - accuracy: 0.0347\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 5.5133 - accuracy: 0.0306\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 5.2015 - accuracy: 0.0510\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 4.8181 - accuracy: 0.0735\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 4.3816 - accuracy: 0.1020\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 3.7600 - accuracy: 0.1959\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 3.1641 - accuracy: 0.3102\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 2.5994 - accuracy: 0.4531\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 2.0201 - accuracy: 0.6327\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 1.5118 - accuracy: 0.7469\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 1.0777 - accuracy: 0.8449\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.8146 - accuracy: 0.8673\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.5567 - accuracy: 0.9102\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.4532 - accuracy: 0.9306\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 0.3460 - accuracy: 0.9429\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.2921 - accuracy: 0.9531\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.2396 - accuracy: 0.9612\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.1921 - accuracy: 0.9653\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.1653 - accuracy: 0.9673\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.1555 - accuracy: 0.9694\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.1350 - accuracy: 0.9714\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.1120 - accuracy: 0.9816\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 1s 95ms/step - loss: 0.1101 - accuracy: 0.9837\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 1s 110ms/step - loss: 0.0869 - accuracy: 0.9837\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.0897 - accuracy: 0.9837\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0725 - accuracy: 0.9918\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0746 - accuracy: 0.9857\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0691 - accuracy: 0.9857\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0610 - accuracy: 0.9939\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.0662 - accuracy: 0.9816\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 1s 113ms/step - loss: 0.0471 - accuracy: 0.9939\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.0515 - accuracy: 0.9898\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.0454 - accuracy: 0.9959\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.0481 - accuracy: 0.9878\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.0340 - accuracy: 0.9959\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.0404 - accuracy: 0.9918\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.0384 - accuracy: 0.9898\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.0405 - accuracy: 0.9918\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 0.0354 - accuracy: 0.9898\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.0317 - accuracy: 0.9939\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.0309 - accuracy: 0.9918\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0257 - accuracy: 0.9918\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.0332 - accuracy: 0.9939\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.0347 - accuracy: 0.9878\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.0300 - accuracy: 0.9918\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.0266 - accuracy: 0.9918\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0260 - accuracy: 0.9939Restoring model weights from the end of the best epoch: 45.\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 0.0260 - accuracy: 0.9939\n",
      "Epoch 50: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Embedding(total_words, 100, input_length=max_sequence_len-1),\n",
    "    layers.Bidirectional(layers.LSTM(128)),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(total_words, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.01),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True, verbose=1)\n",
    "\n",
    "history = model.fit(xs, ys, epochs=100, batch_size=64, verbose=1, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ecc88e6-c75f-4605-b4ed-1871fb45b1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ерте ертеде бір елде бай саудагер өмір сүріпті оның байлығы күміс үйінде мал арыстан өмір бай үйіне басқа есімді кейін бай\n"
     ]
    }
   ],
   "source": [
    "def generate_text(seed_text, next_words, temperature=0.8):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        \n",
    "        predicted = model.predict(token_list, verbose=0)[0]\n",
    "        predicted = np.log(predicted + 1e-10) / temperature\n",
    "        exp_preds = np.exp(predicted)\n",
    "        predicted = exp_preds / np.sum(exp_preds)\n",
    "        \n",
    "        predicted_index = np.random.choice(len(predicted), p=predicted)\n",
    "        \n",
    "        if predicted_index == 0 or predicted_index not in tokenizer.index_word:\n",
    "            continue\n",
    "            \n",
    "        output_word = tokenizer.index_word[predicted_index]\n",
    "        seed_text += \" \" + output_word\n",
    "    \n",
    "    return seed_text\n",
    "\n",
    "print(generate_text(\"Ерте\", 20, temperature=1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de650ea-fbed-4060-b54a-944efcc71a18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
