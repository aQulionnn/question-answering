{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72815fa0-d679-4a98-87e9-f5a381e064d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c2f3e6a2-c92b-4ab5-aefa-077e020f6a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunks: 454\n"
     ]
    }
   ],
   "source": [
    "fairy_tales = pd.read_csv(\"../data/fairy_tales.csv\")\n",
    "\n",
    "chunks = []\n",
    "sentences_per_chunk = 3\n",
    "overlap_sentences = 1\n",
    "\n",
    "for title, text in zip(fairy_tales[\"title\"], fairy_tales[\"text\"]):\n",
    "    sentences = [s.strip().lower() for s in re.split(r\"(?<=[.!?])\\s+\", text) if s.strip()]\n",
    "\n",
    "    i = 0\n",
    "    while i < len(sentences):\n",
    "        chunk = \" \".join(sentences[i:i + sentences_per_chunk])\n",
    "        chunks.append(f\"[{title.lower()}] {chunk}\")\n",
    "        i += sentences_per_chunk - overlap_sentences\n",
    "\n",
    "print(f\"chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "26a823a1-6d91-4603-b0db-2125966bfdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f191e923-6940-43b9-9d16-304317e36d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (454, 512)\n"
     ]
    }
   ],
   "source": [
    "embed_model = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual-qa/3\")\n",
    "embeddings = embed_model(tf.constant(chunks))\n",
    "\n",
    "print(f\"shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f369cf50-fedb-42de-a336-4fc845c90ac5",
   "metadata": {},
   "source": [
    "#### USE-QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8cb65fa8-b9d9-4700-92f9-2dcb56e6aa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question, chunks, embeddings):\n",
    "    question_embedding = embed_model([question])\n",
    "\n",
    "    question_norm = tf.nn.l2_normalize(question_embedding, axis=1)\n",
    "    chunks_norm = tf.nn.l2_normalize(embeddings, axis=1)\n",
    "\n",
    "    similarities = tf.matmul(question_norm, chunks_norm, transpose_b=True)\n",
    "    most_similar_idx = tf.argmax(similarities[0]).numpy()\n",
    "    \n",
    "    return chunks[most_similar_idx], similarities[0][most_similar_idx].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1efe75e6-d6d9-4a7b-8587-bcfc0368956c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevance: 0.6541\n",
      "Chunk: [кедейдің үш ұлы] неге жылайсың? — дейді бұлар.— ой, қарақтарым-ай, мен жыламай, кім жыласын? бүгін жалғыз қызымнан айрылып отырмын, — дейді,— е, неге айрылдыңыз?— қарақтарым-ау, не қып дерің бар ма?\n"
     ]
    }
   ],
   "source": [
    "question = \"Мысық нені төгеді?\"\n",
    "chunk, similarity = answer_question(question, chunks, embeddings)\n",
    "\n",
    "print(f\"Relevance: {similarity:.4f}\")\n",
    "print(f\"Chunk: {chunk}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "02721b8f-c633-4889-9f0b-22495b5fab54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevance: 0.7873\n",
      "Chunk: [кедейдің үш ұлы] неге жылайсың? — дейді бұлар.— ой, қарақтарым-ай, мен жыламай, кім жыласын? бүгін жалғыз қызымнан айрылып отырмын, — дейді,— е, неге айрылдыңыз?— қарақтарым-ау, не қып дерің бар ма?\n"
     ]
    }
   ],
   "source": [
    "question = \"Дүкенші мысықтан не сұрайды?\"\n",
    "chunk, similarity = answer_question(question, chunks, embeddings)\n",
    "\n",
    "print(f\"Relevance: {similarity:.4f}\")\n",
    "print(f\"Chunk: {chunk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656a58fe-ddc4-4525-9be3-68360b2f03e2",
   "metadata": {},
   "source": [
    "#### Top-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6608ba72-f115-43e7-b4f5-e374257efdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question, chunks, embeddings):\n",
    "    question_embedding = embed_model([question])\n",
    "\n",
    "    question_norm = tf.nn.l2_normalize(question_embedding, axis=1)\n",
    "    chunks_norm = tf.nn.l2_normalize(embeddings, axis=1)\n",
    "\n",
    "    similarities = tf.matmul(question_norm, chunks_norm, transpose_b=True)[0].numpy()\n",
    "\n",
    "    most_similar_idx = similarities.argsort()[-3:][::-1]\n",
    "\n",
    "    return [(chunks[i], similarities[i]) for i in most_similar_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c7a0bf4f-284b-49cf-ac41-5db329977604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevance: 0.6541 \n",
      "Chunk: [кедейдің үш ұлы] неге жылайсың? — дейді бұлар.— ой, қарақтарым-ай, мен жыламай, кім жыласын? бүгін жалғыз қызымнан айрылып отырмын, — дейді,— е, неге айрылдыңыз?— қарақтарым-ау, не қып дерің бар ма?\n",
      "\n",
      "Relevance: 0.6498 \n",
      "Chunk: [аяз би] хан не дерін білмей, халыққа қарап:— апырым-ау, мына жаман не дейді! халқым, мен хан баласымын деп жүр едім, шақырыңдар анамды! — дейді.— ол о дүниеге біреудің қанын жүктеп барып, тәңірі алдында қара бет болмасын, не де болса шынын айтсын.\n",
      "\n",
      "Relevance: 0.6440 \n",
      "Chunk: [кедейдің үш ұлы] хан жылап көрісіп:— е, неғып босадың? — дейді.— бір жігіт келіп айдаһарды өлтіріп, мені тірі алып қалды, — дейді.— ол жігіт қайда?— қашып кетті.— қайда қашып кетті? неге айрылдың?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"Мысық нені төгеді?\"\n",
    "results = answer_question(question, chunks, embeddings)\n",
    "\n",
    "for chunk, similarity in results:\n",
    "    print(f\"Relevance: {similarity:.4f} \\nChunk: {chunk}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "836c9133-604b-4beb-975c-9286a1b0c7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevance: 0.7873 \n",
      "Chunk: [кедейдің үш ұлы] неге жылайсың? — дейді бұлар.— ой, қарақтарым-ай, мен жыламай, кім жыласын? бүгін жалғыз қызымнан айрылып отырмын, — дейді,— е, неге айрылдыңыз?— қарақтарым-ау, не қып дерің бар ма?\n",
      "\n",
      "Relevance: 0.7362 \n",
      "Chunk: [аяз би] хан не дерін білмей, халыққа қарап:— апырым-ау, мына жаман не дейді! халқым, мен хан баласымын деп жүр едім, шақырыңдар анамды! — дейді.— ол о дүниеге біреудің қанын жүктеп барып, тәңірі алдында қара бет болмасын, не де болса шынын айтсын.\n",
      "\n",
      "Relevance: 0.7347 \n",
      "Chunk: [кедейдің үш ұлы] хан жылап көрісіп:— е, неғып босадың? — дейді.— бір жігіт келіп айдаһарды өлтіріп, мені тірі алып қалды, — дейді.— ол жігіт қайда?— қашып кетті.— қайда қашып кетті? неге айрылдың?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"Дүкенші мысықтан не сұрайды?\"\n",
    "results = answer_question(question, chunks, embeddings)\n",
    "\n",
    "for chunk, similarity in results:\n",
    "    print(f\"Relevance: {similarity:.4f} \\nChunk: {chunk}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea45685-301e-4f98-8826-881d90ff8165",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "689e9c8f-5400-44f8-bcfb-9743f12ab195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question, chunks, embeddings):\n",
    "    question_embedding = embed_model([question])\n",
    "\n",
    "    question_norm = tf.nn.l2_normalize(question_embedding, axis=1)\n",
    "    chunks_norm = tf.nn.l2_normalize(embeddings, axis=1)\n",
    "\n",
    "    similarities = tf.matmul(question_norm, chunks_norm, transpose_b=True)[0].numpy()\n",
    "\n",
    "    most_similar_idx = similarities.argsort()[-3:][::-1]\n",
    "\n",
    "    return most_similar_idx, similarities[most_similar_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8b6ce081-746c-4b62-9390-f23c068c5c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1b76087b-21d4-42cc-aaf5-e08a5e4897a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[кедейдің үш ұлы] неге жылайсың? — дейді бұлар.— ой, қарақтарым-ай, мен жыламай, кім жыласын? бүгін жалғыз қызымнан айрылып отырмын, — дейді,— е, неге айрылдыңыз?— қарақтарым-ау, не қып дерің бар ма?\n"
     ]
    }
   ],
   "source": [
    "question = \"Мысық нені төгеді?\"\n",
    "relevant_chunks, similarities = answer_question(question, chunks, embeddings)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "texts = [question] + [chunks[i] for i in relevant_chunks]\n",
    "tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "\n",
    "tfidf_scores = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:])[0]\n",
    "\n",
    "combined = 0.6 * similarities + 0.4 * tfidf_scores\n",
    "most_relevant_chunk = relevant_chunks[combined.argmax()]\n",
    "\n",
    "print(chunks[most_relevant_chunk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "df383775-245e-4db6-bbfb-1ae74bff6bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[кедейдің үш ұлы] неге жылайсың? — дейді бұлар.— ой, қарақтарым-ай, мен жыламай, кім жыласын? бүгін жалғыз қызымнан айрылып отырмын, — дейді,— е, неге айрылдыңыз?— қарақтарым-ау, не қып дерің бар ма?\n"
     ]
    }
   ],
   "source": [
    "question = \"Дүкенші мысықтан не сұрайды?\"\n",
    "relevant_chunks, similarities = answer_question(question, chunks, embeddings)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "texts = [question] + [chunks[i] for i in relevant_chunks]\n",
    "tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "\n",
    "tfidf_scores = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:])[0]\n",
    "\n",
    "combined = 0.6 * similarities + 0.4 * tfidf_scores\n",
    "most_relevant_chunk = relevant_chunks[combined.argmax()]\n",
    "\n",
    "print(chunks[most_relevant_chunk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa80b99-2717-4be5-9d58-5fc7135d3e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
